
Start vocab building train...

  0%|▎                                                                                                 | 2012/739345 [00:03<20:11, 608.54it/s]
Finish

  0%|▍                                                                                                 | 3000/739345 [00:05<20:58, 585.02it/s]
21.326604
LR:  0.001






















































Epoch: 0/19 Phase: train Loss: 0.0003 (0.0516) Acc: 0.9729 (0.9980):  99%|███████████████████████████████▌| 2961/3001 [01:49<00:01, 26.95it/s]
Epoch: 0/19 Phase: train Loss: 0.0003 (0.0629) Acc: 0.9729 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.99it/s]























































Epoch: 1/19 Phase: train Loss: 0.0003 (0.0880) Acc: 0.9792 (0.9883):  99%|███████████████████████████████▋| 2976/3001 [01:50<00:00, 27.11it/s]
Epoch: 1/19 Phase: train Loss: 0.0003 (0.0621) Acc: 0.9792 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.91it/s]























































Epoch: 2/19 Phase: train Loss: 0.0003 (0.1294) Acc: 0.9796 (0.9824):  99%|███████████████████████████████▊| 2985/3001 [01:51<00:00, 26.90it/s]
Epoch: 2/19 Phase: train Loss: 0.0003 (0.0705) Acc: 0.9796 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.90it/s]






















































Epoch: 3/19 Phase: train Loss: 0.0003 (0.0637) Acc: 0.9803 (0.9941):  98%|███████████████████████████████▌| 2955/3001 [01:49<00:01, 26.92it/s]
Epoch: 3/19 Phase: train Loss: 0.0003 (0.0628) Acc: 0.9803 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.88it/s]























































Epoch: 4/19 Phase: train Loss: 0.0003 (0.0738) Acc: 0.9802 (0.9902):  99%|███████████████████████████████▊| 2982/3001 [01:50<00:00, 26.86it/s]
Epoch: 4/19 Phase: train Loss: 0.0003 (0.0612) Acc: 0.9803 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.93it/s]























































Epoch: 5/19 Phase: train Loss: 0.0003 (0.1587) Acc: 0.9805 (0.9824): 100%|███████████████████████████████▉| 2991/3001 [01:51<00:00, 26.99it/s]
Epoch: 5/19 Phase: train Loss: 0.0003 (0.0596) Acc: 0.9805 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.90it/s]






















































Epoch: 6/19 Phase: train Loss: 0.0003 (0.0420) Acc: 0.9805 (0.9960): 100%|████████████████████████████████| 3001/3001 [01:51<00:00, 26.91it/s]
Epoch: 7/19 Phase: train Loss: 0.0003 (0.2163) Acc: 0.9761 (0.9648):   0%|                                   | 3/3001 [00:00<02:00, 24.85it/s]





















Epoch: 7/19 Phase: train Loss: 0.0003 (0.6689) Acc: 0.9807 (0.8906):  39%|████████████▎                   | 1159/3001 [00:43<01:08, 26.93it/s]
Traceback (most recent call last):
  File "train.py", line 254, in <module>
    args.lam,
  File "train.py", line 79, in train
    outputs = model(seqs)
  File "/root/virtualenvs/pytorch_1.4/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/root/konst/ml-utils/training/ner_employment/model.py", line 28, in forward
    out, (h,c) = self.bilstm(word_embedding) #'out' has dimension(batchsize, seq_len, 2*hidden_size)
  File "/root/virtualenvs/pytorch_1.4/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/root/virtualenvs/pytorch_1.4/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 559, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
KeyboardInterrupt