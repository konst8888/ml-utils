
[34m[1mwandb[39m[22m: [33mWARNING[39m Symlinked 4 files into the W&B run directory, call wandb.save again to sync new files.
Vocab size: 164
Vocab size: 164
Epoch: 0/199 Phase: train Loss: 0.5933 (0.5933) Acc: 0.7188 (0.7188) Prec 1: 0.0000 (0.0000):   0%|    | 1/4343 [00:00<15:51,  4.56it/s]
0.381102
[544244, 11625]























































































































































































































Epoch: 0/199 Phase: train Loss: -0.1784 (-0.6684) Acc: 0.8948 (0.9032) Prec 1: 0.1365 (1.0000): 100%|â–ˆ| 4343/4343 [07:12<00:00, 10.03it/































































Epoch: 0/199 Phase: valid Loss: -0.6553 (-0.3212) Acc: 0.9445 (0.9000) Prec 1: 0.2542 (nan):  99%|â–ˆâ–‰| 6886/6949 [02:06<00:01, 55.03it/s]
Epoch: 0/199 Phase: valid Loss: -0.6553 (-0.7172) Acc: 0.9444 (1.0000) Prec 1: 0.2542 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:07<00:00, 54.34it/s]



































































































































































































Epoch: 1/199 Phase: train Loss: -0.5645 (-0.0555) Acc: 0.9374 (0.9785) Prec 1: 0.2312 (0.5000): 100%|â–ˆ| 4343/4343 [06:31<00:00, 11.09it/






























































Epoch: 1/199 Phase: valid Loss: -0.8014 (-1.0390) Acc: 0.9607 (1.0000) Prec 1: 0.3349 (1.0000):  99%|â–‰| 6911/6949 [02:06<00:00, 54.81it/
Epoch: 1/199 Phase: valid Loss: -0.8012 (-1.2430) Acc: 0.9606 (1.0000) Prec 1: 0.3353 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:06<00:00, 54.74it/s]































































































































































































Epoch: 2/199 Phase: train Loss: -0.6997 (0.0712) Acc: 0.9477 (0.9462) Prec 1: 0.2702 (0.5000): 100%|â–ˆ| 4343/4343 [06:24<00:00, 11.29it/s






























































Epoch: 2/199 Phase: valid Loss: -0.8355 (-1.1037) Acc: 0.9544 (1.0000) Prec 1: 0.3069 (nan):  99%|â–ˆâ–‰| 6875/6949 [02:05<00:01, 55.12it/s]
Epoch: 2/199 Phase: valid Loss: -0.8352 (-0.2846) Acc: 0.9543 (0.8750) Prec 1: 0.3065 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:06<00:00, 54.81it/s]
































































































































































































Epoch: 3/199 Phase: train Loss: -0.7502 (-0.9532) Acc: 0.9501 (0.9570) Prec 1: 0.2817 (1.0000): 100%|â–ˆ| 4343/4343 [06:25<00:00, 11.26it/






























































Epoch: 3/199 Phase: valid Loss: -0.8220 (-1.0090) Acc: 0.9474 (1.0000) Prec 1: 0.2770 (nan):  99%|â–ˆâ–‰| 6875/6949 [02:05<00:01, 54.84it/s]
Epoch: 3/199 Phase: valid Loss: -0.8226 (-0.9996) Acc: 0.9473 (1.0000) Prec 1: 0.2773 (1.0000): 100%|â–ˆ| 6949/6949 [02:07<00:00, 54.60it/

































































































































































































Epoch: 4/199 Phase: train Loss: -0.7870 (-0.8480) Acc: 0.9551 (0.9677) Prec 1: 0.3055 (nan): 100%|â–ˆâ–ˆ| 4343/4343 [06:27<00:00, 11.20it/s]































































Epoch: 4/199 Phase: valid Loss: -0.9030 (-1.1331) Acc: 0.9618 (1.0000) Prec 1: 0.3477 (1.0000): 100%|â–‰| 6947/6949 [02:07<00:00, 54.89it/
Epoch: 4/199 Phase: valid Loss: -0.9026 (-1.0059) Acc: 0.9617 (1.0000) Prec 1: 0.3477 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:07<00:00, 54.43it/s]































































































































































































Epoch: 5/199 Phase: train Loss: -0.8118 (-0.7861) Acc: 0.9567 (0.9355) Prec 1: 0.3146 (1.0000): 100%|â–ˆ| 4343/4343 [06:25<00:00, 11.26it/































































Epoch: 5/199 Phase: valid Loss: -0.9118 (-1.0015) Acc: 0.9633 (0.9500) Prec 1: 0.3564 (nan):  99%|â–ˆâ–‰| 6910/6949 [02:07<00:00, 54.81it/s]
Epoch: 5/199 Phase: valid Loss: -0.9124 (-0.9550) Acc: 0.9632 (0.8750) Prec 1: 0.3567 (1.0000): 100%|â–ˆ| 6949/6949 [02:08<00:00, 54.27it/
































































































































































































Epoch: 6/199 Phase: train Loss: -0.8339 (-0.9058) Acc: 0.9570 (0.9355) Prec 1: 0.3171 (nan): 100%|â–ˆâ–ˆ| 4343/4343 [06:25<00:00, 11.25it/s]






























































Epoch: 6/199 Phase: valid Loss: -0.8685 (-0.9718) Acc: 0.9524 (1.0000) Prec 1: 0.2984 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:07<00:00, 54.53it/s]
Epoch: 7/199 Phase: train Loss: -0.7824 (-0.9470) Acc: 0.9544 (0.9688) Prec 1: 0.2667 (1.0000):   0%|  | 5/4343 [00:00<06:34, 10.99it/s]






























































































































































































Epoch: 7/199 Phase: train Loss: -0.8505 (1.8284) Acc: 0.9574 (0.9355) Prec 1: 0.3195 (0.5000): 100%|â–ˆ| 4343/4343 [06:22<00:00, 11.36it/s































































Epoch: 7/199 Phase: valid Loss: -0.9308 (-1.1389) Acc: 0.9684 (1.0000) Prec 1: 0.3936 (nan): 100%|â–ˆâ–‰| 6929/6949 [02:07<00:00, 52.48it/s]
Epoch: 7/199 Phase: valid Loss: -0.9312 (-1.2675) Acc: 0.9683 (1.0000) Prec 1: 0.3938 (nan): 100%|â–ˆâ–ˆ| 6949/6949 [02:07<00:00, 54.43it/s]



























































































































































Epoch: 8/199 Phase: train Loss: -0.8453 (-1.0117) Acc: 0.9575 (0.9766) Prec 1: 0.3205 (nan):  81%|â–ˆâ–‹| 3530/4343 [05:13<01:12, 11.25it/s]
Traceback (most recent call last):
  File "train.py", line 342, in <module>
    wandb,
  File "train.py", line 112, in train
    loss.backward()
  File "/usr/local/lib/python3.6/dist-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py", line 149, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
