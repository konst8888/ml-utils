
[34m[1mwandb[39m[22m: [33mWARNING[39m Symlinked 4 files into the W&B run directory, call wandb.save again to sync new files.
/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  mask |= (ar1 == a)
/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison
  mask |= (ar1 == a)
4.873602
Loaded: 11/11
[977960, 81108]
LR:  0.001






























































































































































































































































































































































































































































































































































































































































































Epoch: 0/99 Phase: train Loss: 0.3334 (0.3637) Acc: 0.8001 (0.8468) Rec 1: 0.9001 (0.8333): 100%|█████████████████| 8274/8274 [22:26<00:00,  6.15it/s]






































































Epoch: 0/99 Phase: valid Loss: 0.6044 (0.5136) Acc: 0.0935 (0.6000) Rec 1: 0.9320 (1.0000): 100%|████████████████▉| 4274/4277 [02:21<00:00, 30.35it/s]
Epoch: 0/99 Phase: valid Loss: 0.6045 (0.5353) Acc: 0.0935 (0.7500) Rec 1: 0.9320 (nan): 100%|████████████████████| 4277/4277 [02:21<00:00, 30.30it/s]






























































































































































































































































































































































































































































































































































































































































































Epoch: 1/99 Phase: train Loss: 0.3296 (0.4044) Acc: 0.8035 (0.7177) Rec 1: 0.9015 (0.8333): 100%|█████████████████| 8274/8274 [22:29<00:00,  6.13it/s]





































































Epoch: 1/99 Phase: valid Loss: 0.5511 (0.6004) Acc: 0.0993 (0.7500) Rec 1: 0.9146 (nan): 100%|████████████████████| 4277/4277 [02:21<00:00, 30.26it/s]
Epoch: 2/99 Phase: train Loss: 0.4046 (0.3856) Acc: 0.8021 (0.7812) Rec 1: 0.8182 (0.8750):   0%|                    | 3/8274 [00:00<24:01,  5.74it/s]














































































































































































































































































































































































































































































































































































































































































































Epoch: 2/99 Phase: train Loss: 0.3273 (0.4899) Acc: 0.8041 (0.8145) Rec 1: 0.9038 (0.5000): 100%|█████████████████| 8274/8274 [22:56<00:00,  6.01it/s]





































































Epoch: 2/99 Phase: valid Loss: 0.6516 (0.8054) Acc: 0.0952 (0.7000) Rec 1: 0.9000 (nan):  99%|███████████████████▊| 4229/4277 [02:19<00:01, 30.49it/s]
Epoch: 2/99 Phase: valid Loss: 0.6515 (1.2504) Acc: 0.0952 (0.2500) Rec 1: 0.9003 (nan): 100%|████████████████████| 4277/4277 [02:21<00:00, 30.31it/s]













































































































































































































































































































































































Epoch: 3/99 Phase: train Loss: 0.3261 (0.3535) Acc: 0.8067 (0.7969) Rec 1: 0.9019 (0.7500):  54%|█████████▏       | 4444/8274 [12:14<10:33,  6.05it/s][34m[1mwandb[39m[22m: Network error resolved after 0:10:41.049756, resuming normal operation.



























































































































































































































































































































Epoch: 3/99 Phase: train Loss: 0.3246 (0.3129) Acc: 0.8076 (0.8548) Rec 1: 0.9031 (0.7778): 100%|█████████████████| 8274/8274 [22:47<00:00,  6.05it/s]





































































Epoch: 3/99 Phase: valid Loss: 0.5602 (0.4465) Acc: 0.0996 (0.5500) Rec 1: 0.9189 (1.0000):  99%|████████████████▉| 4247/4277 [02:20<00:00, 30.45it/s]
Epoch: 3/99 Phase: valid Loss: 0.5600 (0.4016) Acc: 0.0996 (0.5000) Rec 1: 0.9178 (nan): 100%|████████████████████| 4277/4277 [02:21<00:00, 30.29it/s]































































































































































































Epoch: 4/99 Phase: train Loss: 0.3228 (0.3268) Acc: 0.8066 (0.7578) Rec 1: 0.9069 (1.0000):  29%|████▉            | 2384/8274 [06:26<15:54,  6.17it/s]
Traceback (most recent call last):
  File "train.py", line 326, in <module>
    wandb,
  File "train.py", line 106, in train
    loss.backward()
  File "/usr/local/lib/python3.6/dist-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py", line 149, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
