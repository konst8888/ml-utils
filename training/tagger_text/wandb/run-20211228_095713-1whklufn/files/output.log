
[34m[1mwandb[39m[22m: [33mWARNING[39m Symlinked 4 files into the W&B run directory, call wandb.save again to sync new files.
Vocab size:  103
Vocab size:  103
Epoch: 0/199 Phase: train Loss: 3.6267 (3.6267) Acc: 0.0000 (0.0000) Prec arts: nan (0.0000):   0%|       | 1/1723 [00:00<13:28,  2.13it/s]
0.849537
[1448, 8259, 699, 5888, 65184, 2394, 31590, 1192, 895, 284, 23028, 3399, 6016, 30723, 2644, 6337, 1004, 1220, 2263, 2048, 313, 620, 1487, 1228, 2888, 924, 1043, 1123, 1107, 2972, 867, 738, 2736, 816, 426, 1995, 2692]
























































































































































































































































































































































































Epoch: 0/199 Phase: train Loss: 3.2411 (2.6469) Acc: 0.1040 (0.2297) Prec arts: 0.0582 (0.0000): 100%|â–ˆ| 1723/1723 [12:36<00:00,  2.28it/s]



























































































































































Epoch: 0/199 Phase: valid Loss: 3.3283 (3.9348) Acc: 0.1545 (0.1500) Prec arts: 0.0465 (nan): 100%|â–ˆâ–ˆâ–ˆâ–‰| 2747/2757 [05:10<00:01,  8.84it/s]
Epoch: 0/199 Phase: valid Loss: 3.3276 (1.8751) Acc: 0.1546 (0.2353) Prec arts: 0.0465 (nan): 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2757/2757 [05:12<00:00,  8.83it/s]



































































































































































































































































































































































































Epoch: 1/199 Phase: train Loss: 2.8283 (2.5205) Acc: 0.2433 (0.4189) Prec arts: 0.0926 (0.0000): 100%|â–ˆ| 1723/1723 [12:58<00:00,  2.21it/s]

























































































































































Epoch: 1/199 Phase: valid Loss: 3.0812 (2.8675) Acc: 0.3478 (0.2353) Prec arts: 0.0697 (nan): 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2757/2757 [05:09<00:00,  8.91it/s]
  0%|                                                                                                             | 0/1723 [00:00<?, ?it/s]




































































































































































































































































































































































































Epoch: 2/199 Phase: train Loss: 2.2369 (2.1921) Acc: 0.4089 (0.5676) Prec arts: 0.1644 (0.2500): 100%|â–ˆ| 1723/1723 [12:59<00:00,  2.21it/s]

























































































































































Epoch: 2/199 Phase: valid Loss: 2.6483 (3.0818) Acc: 0.4242 (0.6471) Prec arts: 0.2358 (0.0000): 100%|â–ˆ| 2757/2757 [05:09<00:00,  8.92it/s]
Epoch: 3/199 Phase: train Loss: 2.0152 (2.0152) Acc: 0.4219 (0.4219) Prec arts: 0.0000 (0.0000):   0%|    | 1/1723 [00:00<12:38,  2.27it/s]





































































































































































































































































































































































































Epoch: 3/199 Phase: train Loss: 1.8916 (1.8035) Acc: 0.4759 (0.5135) Prec arts: 0.3907 (0.6000): 100%|â–ˆ| 1723/1723 [13:01<00:00,  2.21it/s]























































































































































Epoch: 3/199 Phase: valid Loss: 2.5219 (2.1501) Acc: 0.4264 (0.3529) Prec arts: 0.4719 (nan): 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2757/2757 [05:05<00:00,  9.02it/s]
  0%|                                                                                                             | 0/1723 [00:00<?, ?it/s]




































































































































































































































































































































































































Epoch: 4/199 Phase: train Loss: 1.6478 (1.0926) Acc: 0.5194 (0.5676) Prec arts: 0.5164 (0.0000): 100%|â–ˆ| 1723/1723 [13:00<00:00,  2.21it/s]



























































































































































Epoch: 4/199 Phase: valid Loss: 2.2063 (1.8084) Acc: 0.4857 (0.5294) Prec arts: 0.5046 (0.0000): 100%|â–ˆ| 2757/2757 [05:11<00:00,  8.84it/s]
Epoch: 5/199 Phase: train Loss: 1.5123 (1.5568) Acc: 0.5391 (0.5625) Prec arts: 0.5714 (0.2857):   0%|    | 3/1723 [00:01<12:58,  2.21it/s]




































































































































































































































































































































































































Epoch: 5/199 Phase: train Loss: 1.4781 (1.5142) Acc: 0.5471 (0.5270) Prec arts: 0.5266 (0.5000): 100%|â–ˆ| 1723/1723 [13:00<00:00,  2.21it/s]


























































































































































Epoch: 5/199 Phase: valid Loss: 2.2027 (1.6325) Acc: 0.4984 (0.4000) Prec arts: 0.5122 (0.5000):  99%|â–‰| 2742/2757 [05:09<00:01,  8.89it/s]
Epoch: 5/199 Phase: valid Loss: 2.2029 (1.0459) Acc: 0.4985 (0.7059) Prec arts: 0.5131 (nan): 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 2757/2757 [05:11<00:00,  8.86it/s]





































































































































Epoch: 6/199 Phase: train Loss: 1.3415 (1.5797) Acc: 0.5665 (0.5391) Prec arts: 0.5415 (0.0000):  34%|â–‹ | 589/1723 [04:28<08:36,  2.20it/s]
Traceback (most recent call last):
  File "train.py", line 355, in <module>
    wandb,
  File "train.py", line 92, in train
    for idx, sample in pbar:
  File "/usr/local/lib/python3.6/dist-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/konst/ml-utils/training/tagger_text/dataset.py", line 158, in __getitem__
    tokens = [self.encode_char(t) for t in tokens]
  File "/root/konst/ml-utils/training/tagger_text/dataset.py", line 158, in <listcomp>
    tokens = [self.encode_char(t) for t in tokens]
  File "/root/konst/ml-utils/training/tagger_text/dataset.py", line 128, in encode_char
    char = char.encode('unicode-escape').decode('ASCII')
