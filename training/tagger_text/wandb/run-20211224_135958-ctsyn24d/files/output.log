
[34m[1mwandb[39m[22m: [33mWARNING[39m Symlinked 4 files into the W&B run directory, call wandb.save again to sync new files.
Vocab size:  1000
Vocab size:  1000
2.285437
[1448, 8286, 699, 5888, 65188, 2394, 31596, 1198, 595, 158, 23031, 3399, 6016, 30726, 2644, 6337, 1007, 1220, 2263, 2061, 313, 620, 1488, 1228, 2888, 924, 1043, 1123, 1107, 2972, 867, 739, 2736, 816, 427, 1995, 2692]
LR:  0.001




















































































































































Epoch: 0/199 Phase: train Loss: 3.4604 (3.4841) Acc: 0.0222 (0.0078) Prec arts: 0.0000 (0.0000):  26%|â–Œ | 447/1720 [05:07<14:34,  1.46it/s]
Traceback (most recent call last):
  File "train.py", line 352, in <module>
    wandb,
  File "train.py", line 90, in train
    for idx, sample in pbar:
  File "/usr/local/lib/python3.6/dist-packages/tqdm/std.py", line 1185, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/konst/ml-utils/training/tagger_text/dataset.py", line 155, in __getitem__
    text = self.transforms(text)
  File "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py", line 67, in __call__
    img = t(img)
  File "/root/konst/ml-utils/training/tagger_text/utils.py", line 26, in uppercase
    tokens = tokenize(x, include_space=True)
  File "/root/konst/ml-utils/training/tagger_text/utils.py", line 17, in tokenize
    em_split_emoji = emoji.get_emoji_regexp().split(text)
KeyboardInterrupt